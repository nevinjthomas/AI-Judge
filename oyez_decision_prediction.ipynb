{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ecd86e2",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d84fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install pandas\n",
    "#%pip install numpy\n",
    "#%pip install sklearn\n",
    "#%pip install xgboost\n",
    "#%pip install lightgbm\n",
    "\n",
    "#For additional data pre-proccessing & augmentation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import wordnet\n",
    "import random\n",
    "\n",
    "#For splitting and formating data for training\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#For evaluating models\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "#Models\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17342c68",
   "metadata": {},
   "source": [
    "# 1. Dataset Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d815ec89",
   "metadata": {},
   "source": [
    "## Load & Augment Pre-processed Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74897779",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_o = pd.read_pickle('cleaned_cases.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652c6a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54de1f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def synonym_replacement(text):\n",
    "    if not text:\n",
    "        return ''\n",
    "\n",
    "    words = text.split()\n",
    "    new_words = words.copy()\n",
    "    random_word_list = list(set([word for word in words if wordnet.synsets(word)]))\n",
    "    random.shuffle(random_word_list)\n",
    "    num_replacements = max(1, int(0.1 * len(words)))  # Replace around 10% of the words\n",
    "\n",
    "    replacements = 0\n",
    "    for random_word in random_word_list:\n",
    "        synonyms = wordnet.synsets(random_word)\n",
    "        if synonyms:\n",
    "            synonym = synonyms[0].lemmas()[0].name()\n",
    "            new_words = [synonym if word == random_word else word for word in new_words]\n",
    "            replacements += 1\n",
    "        if replacements >= num_replacements:\n",
    "            break\n",
    "\n",
    "    return ' '.join(new_words)\n",
    "\n",
    "def mirror_case(row):\n",
    "    return {\n",
    "        'name': f\"{row['name']} (Mirrored)\",\n",
    "        'first_party': row['second_party'],\n",
    "        'second_party': row['first_party'],\n",
    "        'winning_party': row['winning_party'],\n",
    "        'Facts': synonym_replacement(row['Facts']),\n",
    "        'question': synonym_replacement(row['question']),\n",
    "        'conclusion': synonym_replacement(row['conclusion']),\n",
    "        'winner_index': 1 - row['winner_index']\n",
    "    }\n",
    "\n",
    "mirrored = []\n",
    "for index, row in df_o.iterrows():\n",
    "    mirrored.append(mirror_case(row))\n",
    "df_m = pd.DataFrame(mirrored)\n",
    "\n",
    "df = pd.concat([df_o, df_m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "761f95bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cases: 6928\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>first_party</th>\n",
       "      <th>second_party</th>\n",
       "      <th>winning_party</th>\n",
       "      <th>question</th>\n",
       "      <th>conclusion</th>\n",
       "      <th>winner_index</th>\n",
       "      <th>Facts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1749</th>\n",
       "      <td>Brandenburg v. Ohio (Mirrored)</td>\n",
       "      <td>State of Ohio</td>\n",
       "      <td>Clarence Brandenburg</td>\n",
       "      <td>Brandenburg</td>\n",
       "      <td>Did Ohio's criminal syndicalism law, prohibiting public speech that advocates assorted illegal activities, violate Brandenburg's right to free speech as protected by the First and Fourteenth Amendments?</td>\n",
       "      <td>The Court's Per Curiam opinion held that the Ohio law violated Brandenburg's right to free speech. The Court used angstrom two-pronged test to measure speech acts: (1) speech can be prohibited if it is \"directed at motivate or producing imminent lawless action\" and (2) it is \"likely to incite or produce such action.\" The criminal syndicalism act made illegal the advocacy and teaching of doctrines while ignoring whether or not that advocacy and teaching would actually incite imminent lawless action. The failure to brand this differentiation rendered the law overly broad and in misdemeanor of the Constitution.</td>\n",
       "      <td>1</td>\n",
       "      <td>Brandenburg, a leader in the Ku Klux Klan, made a speech at a Klan rally and was later convicted under an Ohio criminal syndicalism law. The law made illegal recommend \"crime, sabotage, violence, or improper methods of terrorism arsenic a means of accomplishing industrial or political reform,\" arsenic well arsenic assembling \"with any society, group, or assemblage of persons formed to Teach or advocate the doctrines of criminal syndicalism.\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                name    first_party          second_party  \\\n",
       "1749  Brandenburg v. Ohio (Mirrored)  State of Ohio  Clarence Brandenburg   \n",
       "\n",
       "     winning_party  \\\n",
       "1749   Brandenburg   \n",
       "\n",
       "                                                                                                                                                                                                        question  \\\n",
       "1749  Did Ohio's criminal syndicalism law, prohibiting public speech that advocates assorted illegal activities, violate Brandenburg's right to free speech as protected by the First and Fourteenth Amendments?   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   conclusion  \\\n",
       "1749  The Court's Per Curiam opinion held that the Ohio law violated Brandenburg's right to free speech. The Court used angstrom two-pronged test to measure speech acts: (1) speech can be prohibited if it is \"directed at motivate or producing imminent lawless action\" and (2) it is \"likely to incite or produce such action.\" The criminal syndicalism act made illegal the advocacy and teaching of doctrines while ignoring whether or not that advocacy and teaching would actually incite imminent lawless action. The failure to brand this differentiation rendered the law overly broad and in misdemeanor of the Constitution.   \n",
       "\n",
       "      winner_index  \\\n",
       "1749             1   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                              Facts  \n",
       "1749  Brandenburg, a leader in the Ku Klux Klan, made a speech at a Klan rally and was later convicted under an Ohio criminal syndicalism law. The law made illegal recommend \"crime, sabotage, violence, or improper methods of terrorism arsenic a means of accomplishing industrial or political reform,\" arsenic well arsenic assembling \"with any society, group, or assemblage of persons formed to Teach or advocate the doctrines of criminal syndicalism.\"  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Cases: {len(df)}')\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "df.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f4afca",
   "metadata": {},
   "source": [
    "# 2. AI Judge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f37cb2",
   "metadata": {},
   "source": [
    "Splitting and Preparing Data for Neural Network Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "71a68709",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_party1_text, X_test_party1_text, \\\n",
    "X_train_party2_text, X_test_party2_text, \\\n",
    "X_train_facts_text, X_test_facts_text, \\\n",
    "y_train, y_test = train_test_split(\n",
    "    df['first_party'],\n",
    "    df['second_party'],\n",
    "    df['Facts'],\n",
    "    df['winner_index'],\n",
    "    test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3b7659be",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_party1 = TfidfVectorizer()\n",
    "vectorizer_party2 = TfidfVectorizer()\n",
    "vectorizer_facts = TfidfVectorizer()\n",
    "\n",
    "X_train_party1 = vectorizer_party1.fit_transform(X_train_party1_text)\n",
    "X_test_party1 = vectorizer_party1.transform(X_test_party1_text)\n",
    "\n",
    "X_train_party2 = vectorizer_party2.fit_transform(X_train_party2_text)\n",
    "X_test_party2 = vectorizer_party2.transform(X_test_party2_text)\n",
    "\n",
    "X_train_facts = vectorizer_facts.fit_transform(X_train_facts_text)\n",
    "X_test_facts = vectorizer_facts.transform(X_test_facts_text)\n",
    "\n",
    "# Combine features\n",
    "X_train = np.hstack([X_train_party1.toarray(), X_train_party2.toarray(), X_train_facts.toarray()])\n",
    "X_test = np.hstack([X_test_party1.toarray(), X_test_party2.toarray(), X_test_facts.toarray()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98dd0f91",
   "metadata": {},
   "source": [
    "###  KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ac285192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classifier Accuracy:  0.6464646464646465\n"
     ]
    }
   ],
   "source": [
    "knn_classifier = KNeighborsClassifier(n_neighbors= 5, weights = 'distance')\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "\n",
    "knn_predictions = knn_classifier.predict(X_test)\n",
    "print(\"KNN Classifier Accuracy: \", accuracy_score(y_test, knn_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f411e52",
   "metadata": {},
   "source": [
    "###  Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "34c5d16c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Classifier Accuracy:  0.6392496392496393\n"
     ]
    }
   ],
   "source": [
    "nb_classifier = MultinomialNB(alpha = 5)\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "\n",
    "nb_predictions = nb_classifier.predict(X_test)\n",
    "print(\"Naive Bayes Classifier Accuracy: \", accuracy_score(y_test, nb_predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54f7052",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3e779ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classifier Accuracy:  0.6955266955266955\n"
     ]
    }
   ],
   "source": [
    "svm_classifier = LinearSVC(C=0.7, intercept_scaling=0.1, loss='squared_hinge', dual='auto')\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "svm_predictions = svm_classifier.predict(X_test)\n",
    "print(\"SVM Classifier Accuracy: \", accuracy_score(y_test, svm_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf62ac5",
   "metadata": {},
   "source": [
    "###  XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "49146fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Classifier Test Accuracy: 0.7373737373737373\n"
     ]
    }
   ],
   "source": [
    "xgb_classifier = XGBClassifier(random_state=7)\n",
    "xgb_classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred_xgb = xgb_classifier.predict(X_test)\n",
    "xgb_accuracy = accuracy_score(y_test, y_pred_xgb)\n",
    "print(f\"XGBoost Classifier Test Accuracy: {xgb_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09278f0c",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3b971aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM Classifier Test Accuracy: 0.7251082251082251\n"
     ]
    }
   ],
   "source": [
    "lgbm_classifier = LGBMClassifier(random_state=7, verbose = -1)\n",
    "lgbm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_lgbm = lgbm_classifier.predict(X_test)\n",
    "lgbm_accuracy = accuracy_score(y_test, y_pred_lgbm)\n",
    "print(f\"LightGBM Classifier Test Accuracy: {lgbm_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39786ba0",
   "metadata": {},
   "source": [
    "### Log Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0811b10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Test Accuracy: 0.7056277056277056\n"
     ]
    }
   ],
   "source": [
    "log_classifier = LogisticRegression(max_iter=10000, random_state=7)\n",
    "log_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_log_reg = log_classifier.predict(X_test)\n",
    "log_reg_accuracy = accuracy_score(y_test, y_pred_log_reg)\n",
    "print(f\"Logistic Regression Test Accuracy: {log_reg_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f560314",
   "metadata": {},
   "source": [
    "### Voting Classifier Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7cf185f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voting_classifier - Test\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.76      0.72       670\n",
      "           1       0.75      0.67      0.71       716\n",
      "\n",
      "    accuracy                           0.72      1386\n",
      "   macro avg       0.72      0.72      0.72      1386\n",
      "weighted avg       0.72      0.72      0.72      1386\n",
      "\n"
     ]
    }
   ],
   "source": [
    "voting_classifier = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('knn', knn_classifier),\n",
    "        ('nb', nb_classifier),\n",
    "        ('svm', svm_classifier),\n",
    "        ('log', log_classifier),\n",
    "        ('lgbm', lgbm_classifier),\n",
    "        ('xgb', xgb_classifier)\n",
    "    ],\n",
    "    voting='hard'\n",
    ")\n",
    "\n",
    "# Train the voting classifier\n",
    "voting_classifier.fit(X_train, y_train)\n",
    "y_test_pred = voting_classifier.predict(X_test)\n",
    "\n",
    "print('voting_classifier - Test\\n', classification_report(y_test, y_test_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bff744",
   "metadata": {},
   "source": [
    "# 3. Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bd176013",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(party1, party2, facts):\n",
    "    X_party1 = vectorizer_party1.transform([party1]).todense()\n",
    "    X_party2 = vectorizer_party2.transform([party2]).todense()\n",
    "    X_facts = vectorizer_facts.transform([facts]).todense()\n",
    "\n",
    "    # Combine the features\n",
    "    X = np.asarray(np.hstack([X_party1, X_party2, X_facts]))\n",
    "\n",
    "    # Predict the outcome using the voting classifier\n",
    "    win_index = voting_classifier.predict(X)[0]\n",
    "    if (win_index == 0):\n",
    "        return party1\n",
    "    else:\n",
    "         return party2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df77952",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [\n",
    "    'Aurelia Moon',\n",
    "    'Caspian Thorne',\n",
    "    'Aurelia Moon, the owner of a small bakery called \"Moonlit Delights,\" placed an order for a new commercial oven from a supplier. The delivery was scheduled for February 1, 2023. On the delivery day, the supplier\\'s truck was involved in an accident caused by Caspian Thorne, the owner of \"Thorne\\'s Brews,\" who was driving negligently. The oven was damaged and required repairs, leading to a delay in Moon receiving it. As a result, Moon\\'s bakery lost $10,000 in revenue from unfulfilled orders. Moon is suing Thorne for negligence, seeking compensation for the lost revenue. Thorne acknowledges the accident but argues the damages claimed are exaggerated and that Moon should have mitigated her losses by renting a temporary oven. Witnesses confirmed Thorne was speeding, and financial records show Moon\\'s loss in revenue during the repair period. Quotes from local businesses indicate the cost and availability of renting a temporary oven.'\n",
    "]\n",
    "\n",
    "out = predict(test[0],test[1],test[2])\n",
    "print(f'AI Judge rules in favor of {out}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32022122",
   "metadata": {},
   "source": [
    "# 4. AI Judge Decision Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b4233f",
   "metadata": {},
   "source": [
    "### Create a unqieuly trained T-5 small LLM to output reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8261f1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install sentencepiece\n",
    "%pip install accelerate -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a3731a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, Trainer, TrainingArguments\n",
    "import torch\n",
    "\n",
    "# Create input text by combining relevant columns\n",
    "df['input_text'] = df.apply(lambda row: f\"First party: {row['first_party']}, Second party: {row['second_party']}, Facts: {row['Facts']}, Winner index: {row['winner_index']}\", axis=1)\n",
    "df['target_text'] = df['conclusion']\n",
    "\n",
    "# Split data into training and validation sets\n",
    "train_df, val_df = train_test_split(df, test_size=0.2)\n",
    "\n",
    "# Initialize the tokenizer and model\n",
    "model_name = 't5-small'\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846a4514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the inputs and outputs\n",
    "train_encodings = tokenizer(train_df['input_text'].tolist(), truncation=True, padding=True, max_length=512)\n",
    "val_encodings = tokenizer(val_df['input_text'].tolist(), truncation=True, padding=True, max_length=512)\n",
    "\n",
    "train_labels = tokenizer(train_df['target_text'].tolist(), truncation=True, padding=True, max_length=512).input_ids\n",
    "val_labels = tokenizer(val_df['target_text'].tolist(), truncation=True, padding=True, max_length=512).input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f9f37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dataset class\n",
    "class CourtDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = CourtDataset(train_encodings, train_labels)\n",
    "val_dataset = CourtDataset(val_encodings, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9418eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    gradient_accumulation_steps=8,\n",
    ")\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Save the model\n",
    "model.save_pretrained('./court_conclusion_model')\n",
    "tokenizer.save_pretrained('./court_conclusion_tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65af8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained('./court_conclusion_model')\n",
    "tokenizer = T5Tokenizer.from_pretrained('./court_conclusion_tokenizer')\n",
    "\n",
    "# Example new input\n",
    "new_input = \"First party: \" + test[0] + \", Second party: \" + test[1] + \", Facts: \" + test[2]\n",
    "\n",
    "# Tokenize and generate conclusion\n",
    "input_ids = tokenizer(new_input, return_tensors='pt').input_ids\n",
    "\n",
    "# Generate conclusion with adjusted parameters\n",
    "generated_ids = model.generate(\n",
    "    input_ids,\n",
    "    max_length=10000,\n",
    "    num_beams=5,\n",
    "    early_stopping=True,\n",
    "    no_repeat_ngram_size=2,\n",
    "    temperature=0.7,\n",
    "    top_p=0.9,\n",
    ")\n",
    "\n",
    "# Decode the generated text\n",
    "conclusion = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "print('Generated conclusion:\\n',conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf81378",
   "metadata": {},
   "source": [
    "### Use a general pre-trained T-5 model to provide reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308d4b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91624ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7857e5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_reasoning(facts, predicted_winner):\n",
    "    prompt = f\"Facts: {facts} Predicted Winner: {predicted_winner} Reasoning:\"\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
    "    outputs = model.generate(input_ids, max_length=512)\n",
    "    reasoning = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f195380",
   "metadata": {},
   "outputs": [],
   "source": [
    "facts = test[2]\n",
    "\n",
    "predicted_winner = out\n",
    "\n",
    "reasoning = generate_reasoning(facts, predicted_winner)\n",
    "print(reasoning)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
